{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for generating and saving SBM CLUSTER graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import time\n",
    "import networkx as nx\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.sparse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate SBM CLUSTER graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "def schuffle(W,c):\n",
    "    # relabel the vertices at random\n",
    "    idx=np.random.permutation( W.shape[0] )\n",
    "    #idx2=np.argsort(idx) # for index ordering wrt classes\n",
    "    W_new=W[idx,:]\n",
    "    W_new=W_new[:,idx]\n",
    "    c_new=c[idx]\n",
    "    return W_new , c_new , idx \n",
    "\n",
    "\n",
    "def block_model(c,p,q):\n",
    "    n=len(c)\n",
    "    W=np.zeros((n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(i+1,n):\n",
    "            if c[i]==c[j]:\n",
    "                prob=p\n",
    "            else:\n",
    "                prob=q\n",
    "            if np.random.binomial(1,prob)==1:\n",
    "                W[i,j]=1\n",
    "                W[j,i]=1     \n",
    "    return W\n",
    "\n",
    "\n",
    "def unbalanced_block_model(nb_of_clust, clust_size_min, clust_size_max, p, q):  \n",
    "    c = []\n",
    "    for r in range(nb_of_clust):\n",
    "        if clust_size_max==clust_size_min:\n",
    "            clust_size_r = clust_size_max\n",
    "        else:\n",
    "            clust_size_r = np.random.randint(clust_size_min,clust_size_max,size=1)[0]\n",
    "        val_r = np.repeat(r,clust_size_r,axis=0)\n",
    "        c.append(val_r)\n",
    "    c = np.concatenate(c)  \n",
    "    W = block_model(c,p,q)  \n",
    "    return W,c\n",
    "\n",
    "\n",
    "class generate_SBM_graph():\n",
    "\n",
    "    def __init__(self, SBM_parameters): \n",
    "\n",
    "        # parameters\n",
    "        nb_of_clust = SBM_parameters['nb_clusters']\n",
    "        clust_size_min = SBM_parameters['size_min']\n",
    "        clust_size_max = SBM_parameters['size_max']\n",
    "        p = SBM_parameters['p']\n",
    "        q = SBM_parameters['q']\n",
    "\n",
    "        # block model\n",
    "        W, c = unbalanced_block_model(nb_of_clust, clust_size_min, clust_size_max, p, q)\n",
    "        \n",
    "        # shuffle\n",
    "        W, c, idx = schuffle(W,c)\n",
    "        \n",
    "        # signal on block model\n",
    "        u = np.zeros(c.shape[0])\n",
    "        for r in range(nb_of_clust):\n",
    "            cluster = np.where(c==r)[0]\n",
    "            s = cluster[np.random.randint(cluster.shape[0])]\n",
    "            u[s] = r+1\n",
    "\n",
    "        # target\n",
    "        target = c\n",
    "        \n",
    "        # convert to pytorch\n",
    "        W = torch.from_numpy(W)\n",
    "        W = W.to(torch.int8)\n",
    "        idx = torch.from_numpy(idx) \n",
    "        idx = idx.to(torch.int16)\n",
    "        u = torch.from_numpy(u) \n",
    "        u = u.to(torch.int16)                      \n",
    "        target = torch.from_numpy(target)\n",
    "        target = target.to(torch.int16)\n",
    "        \n",
    "        # attributes\n",
    "        self.nb_nodes = W.size(0)\n",
    "        self.W = W\n",
    "        self.rand_idx = idx\n",
    "        self.node_feat = u\n",
    "        self.node_label = target\n",
    "        \n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "# configuration   \n",
    "SBM_parameters = {}\n",
    "SBM_parameters['nb_clusters'] = 6 \n",
    "SBM_parameters['size_min'] = 5 \n",
    "SBM_parameters['size_max'] = 35 \n",
    "SBM_parameters['p'] = 0.55 \n",
    "SBM_parameters['q'] = 0.25 \n",
    "print(SBM_parameters)\n",
    "    \n",
    "\n",
    "data = generate_SBM_graph(SBM_parameters)\n",
    "\n",
    "print(data)\n",
    "#print(data.nb_nodes)\n",
    "#print(data.W)\n",
    "#print(data.rand_idx)\n",
    "#print(data.node_feat)\n",
    "#print(data.node_label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "#Plot Adj matrix\n",
    "\n",
    "W = data.W\n",
    "plt.spy(W,precision=0.01, markersize=1)\n",
    "plt.show()\n",
    "\n",
    "idx = np.argsort(data.rand_idx) \n",
    "W = data.W\n",
    "W2 = W[idx,:]\n",
    "W2 = W2[:,idx]\n",
    "plt.spy(W2,precision=0.01, markersize=1)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Generate and save SBM graphs\n",
    "\n",
    "class DotDict(dict):\n",
    "    def __init__(self, **kwds):\n",
    "        self.update(kwds)\n",
    "        self.__dict__ = self\n",
    "\n",
    "def generate_semisuperclust_dataset(nb_graphs):\n",
    "    dataset = []\n",
    "    for i in range(nb_graphs):\n",
    "        if not i%250:\n",
    "            print(i)\n",
    "        data = generate_SBM_graph(SBM_parameters)\n",
    "        graph = DotDict()\n",
    "        graph.nb_nodes = data.nb_nodes\n",
    "        graph.W = data.W\n",
    "        graph.rand_idx = data.rand_idx\n",
    "        graph.node_feat = data.node_feat\n",
    "        graph.node_label = data.node_label\n",
    "        dataset.append(graph)\n",
    "    return dataset\n",
    "\n",
    "def plot_histo_graphs(dataset, title):\n",
    "    # histogram of graph sizes\n",
    "    graph_sizes = []\n",
    "    for graph in dataset:\n",
    "        graph_sizes.append(graph.nb_nodes)\n",
    "    plt.figure(1)\n",
    "    plt.hist(graph_sizes, bins=50)\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "     \n",
    "def SBMs_CLUSTER(nb_graphs, name):\n",
    "    dataset = generate_semisuperclust_dataset(nb_graphs)\n",
    "    print(len(dataset))\n",
    "    with open(name+'.pkl',\"wb\") as f:\n",
    "        pickle.dump(dataset,f)\n",
    "    plot_histo_graphs(dataset,name)\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "nb_graphs = 10000 # train\n",
    "#nb_graphs = 3333 # train\n",
    "#nb_graphs = 500 # train\n",
    "#nb_graphs = 20 # train\n",
    "SBMs_CLUSTER(nb_graphs, 'SBM_CLUSTER_train')\n",
    "    \n",
    "nb_graphs = 1000 # val\n",
    "#nb_graphs = 333 # val\n",
    "#nb_graphs = 100 # val\n",
    "#nb_graphs = 5 # val\n",
    "SBMs_CLUSTER(nb_graphs, 'SBM_CLUSTER_val')\n",
    "\n",
    "    \n",
    "nb_graphs = 1000 # test\n",
    "#nb_graphs = 333 # test\n",
    "#nb_graphs = 100 # test\n",
    "#nb_graphs = 5 # test\n",
    "SBMs_CLUSTER(nb_graphs, 'SBM_CLUSTER_test')\n",
    "\n",
    "print('Time (sec):',time.time() - start) # 190s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert to DGL format and save with pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../../') # go to root folder of the project\n",
    "print(os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pickle\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from data.SBMs import SBMsDatasetDGL \n",
    "\n",
    "from data.data import LoadData\n",
    "from torch.utils.data import DataLoader\n",
    "from data.SBMs import SBMsDataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'SBM_CLUSTER'\n",
    "dataset = SBMsDatasetDGL(DATASET_NAME)  #3983s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(len(dataset.train))\n",
    "print(len(dataset.val))\n",
    "print(len(dataset.test))\n",
    "\n",
    "print(dataset.train[0])\n",
    "print(dataset.val[0])\n",
    "print(dataset.test[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "with open('data/SBMs/SBM_CLUSTER.pkl','wb') as f:\n",
    "        pickle.dump([dataset.train,dataset.val,dataset.test],f)\n",
    "        \n",
    "print('Time (sec):',time.time() - start)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "DATASET_NAME = 'SBM_CLUSTER'\n",
    "dataset = LoadData(DATASET_NAME) # 29s\n",
    "trainset, valset, testset = dataset.train, dataset.val, dataset.test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "\n",
    "batch_size = 10\n",
    "collate = SBMsDataset.collate\n",
    "print(SBMsDataset)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, collate_fn=collate)\n",
    "\n",
    "print('Time (sec):',time.time() - start) #0.002s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}